---
title: "Introduction to Text Classification"
author: "Julia Silge"
output:
  rmdshower::shower_presentation:
    self_contained: false
    katex: true
    theme: ribbon
---


```{r, echo = FALSE, warning = FALSE}
library(knitr)
knitr::opts_chunk$set(cache = TRUE, warning = FALSE, message = FALSE, dpi = 180)
options(width=80)
library(ggplot2)
library(silgelib)
theme_set(theme_plex())
```

## Text classification { .cover }

<img src="figs/blue_jane.png" height=350>

### Julia Silge (Stack Overflow)

#### [\@juliasilge](https://twitter.com/juliasilge)

#### [https://juliasilge.com/](https://juliasilge.com/)

## Let's install some packages

```{r, eval=FALSE}
install.packages(c("tidyverse", 
                   "tidytext", 
                   "gutenbergr",
                   "glmnet"))
```

# Classification `r emo::ji("sparkles")`

## Downloading your text data

```{r}
library(tidyverse)
library(gutenbergr)

titles <- c("The War of the Worlds",
            "Pride and Prejudice")

books <- gutenberg_works(title %in% titles) %>%
    gutenberg_download(meta_fields = "title") %>%
    mutate(document = row_number())

books
```

## Making a tidy dataset

Use this kind of data structure for EDA! `r emo::ji("nail")`

```{r}
library(tidytext)

tidy_books <- books %>%
    unnest_tokens(word, text) %>%
    group_by(word) %>%
    filter(n() > 50) %>%
    ungroup
```

## Cast to a sparse matrix

And build a dataframe with a response variable

```{r}
sparse_words <- tidy_books %>%
    count(document, word, sort = TRUE) %>%
    cast_sparse(document, word, n)

books_joined <- data_frame(document = as.integer(rownames(sparse_words))) %>%
    left_join(books %>%
                  select(document, title))
```

## Train a glmnet model

```{r}
library(glmnet)
library(doMC)
registerDoMC(cores = 8)

is_jane <- books_joined$title == "Pride and Prejudice"

model <- cv.glmnet(sparse_words, is_jane, family = "binomial", 
                   parallel = TRUE, keep = TRUE)
```

## Tidying our model

```{r}
library(broom)

coefs <- model$glmnet.fit %>%
    tidy() %>%
    tbl_df() %>%     ## filter to choose some lambda from glmnet output
    filter(lambda >= 1.2 * model$lambda.1se) %>% 
    filter(lambda == min(lambda))

Intercept <- coefs %>%
    filter(term == "(Intercept)") %>%
    pull(estimate)
```

## Tidying our model

```{r}
classifications <- tidy_books %>%
    inner_join(coefs, by = c("word" = "term")) %>%
    group_by(document) %>%
    summarize(Score = sum(estimate)) %>%
    mutate(Probability = plogis(Intercept + Score))

classifications
```


## Understanding our model

```{r, eval=FALSE}
coefs %>%
    group_by(estimate > 0) %>%
    top_n(15, abs(estimate)) %>%
    ungroup %>%
    ggplot(aes(fct_reorder(term, estimate), estimate, fill = estimate > 0)) +
    geom_col(show.legend = FALSE) +
    coord_flip()
```

## { .white }

<div class="fullpage width">
```{r, echo = FALSE}
coefs %>%
    group_by(estimate > 0) %>%
    top_n(15, abs(estimate)) %>%
    ungroup %>%
    ggplot(aes(fct_reorder(term, estimate), estimate, fill = estimate > 0)) +
    geom_col(show.legend = FALSE) +
    coord_flip() +
    labs(x = NULL,
         title = "Coefficients that increase/decrease probability of classification",
         subtitle = "A document mentioning Martians is unlikely to be written by Jane Austen")
```
</div>

## ROC

```{r}
comment_classes <- classifications %>%
    left_join(books %>%
                  select(title, document), by = "document") %>%
    mutate(Correct = case_when(title == "Pride and Prejudice" ~ TRUE,
                               TRUE ~ FALSE))

roc <- comment_classes %>%
    arrange(desc(Probability)) %>%
    mutate(TPR = cumsum(Correct) / sum(Correct),
           FPR = cumsum(!Correct) / sum(!Correct),
           FDR = cummean(!Correct))
```

## ROC

```{r}
roc %>%
    arrange(Probability)
```


## { .white }

<div class="fullpage width">
```{r, echo = FALSE}
roc %>%
    arrange(Probability) %>%
    ggplot(aes(FPR, TPR)) +
    geom_abline(lty = 2, alpha = 0.5, 
                color = "gray50",
                size = 1.5) + 
    geom_line(color = "midnightblue",
              size = 1.8) +
    labs(title = "ROC for text classification")
```
</div>


## AUC for model

```{r}
roc %>%
    summarise(AUC = sum(diff(FPR) * na.omit(lead(TPR) + TPR)) / 2)
```

## Misclassifications

Let's talk about misclassifications. Which documents here were incorrectly predicted to be written by Jane Austen?

```{r}
roc %>%
    filter(Probability > .8, !Correct) %>%
    sample_n(10) %>%
    inner_join(books %>%
                   select(document, text)) %>%
    select(Probability, text)
```

## Misclassifications

Let's talk about misclassifications. Which documents here were incorrectly predicted to *not* be written by Jane Austen?

```{r}
roc %>%
    filter(Probability < .2, Correct) %>%
    sample_n(10) %>%
    inner_join(books %>%
                   select(document, text)) %>%
    select(Probability, text)
```


# Workflow for text mining/modeling

##  { .white }

<img src="figs/tmwr_0601.png" class="cover">
